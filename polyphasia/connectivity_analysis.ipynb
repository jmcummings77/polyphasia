{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from networkx.algorithms.traversal import bfs_tree\n",
    "\n",
    "\"\"\"\n",
    "Load data from file\n",
    "\"\"\"\n",
    "\n",
    "# set up some paths for ins and outs\n",
    "base_directory = Path.cwd().parent.absolute()\n",
    "source_data_path = base_directory / \"data\" / \"raw\" / \"etymwn.tsv\"\n",
    "processed_directory = base_directory / \"data\" / \"processed\"\n",
    "output_graph_yaml_file = processed_directory / \"graph_output.yaml\"\n",
    "output_graph_dot_file = processed_directory / \"graph_output.dot\"\n",
    "output_graph_png = processed_directory / \"graph_output.png\"\n",
    "\n",
    "# load from CSV\n",
    "cleaned_df = pd.read_csv(\n",
    "    source_data_path, sep=\"\\t\", names=[\"source_node\", \"edge_type\", \"target_node\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Cleaning notes\n",
    "\n",
    "## Relationship types found in source data\n",
    "\n",
    "Relationships are recorded bidirectionally. So a root word will link to its derivatives, and each derivative will link back to the root. To simplify the graph,\n",
    "I will drop edges that point from derivatives to roots, since that information is already encoded in the root-to-leaf edge and networkx can handle bidirectional\n",
    "traversal without requiring multiple edges to link the same pair of nodes.\n",
    "\n",
    "Below are the types of relationships extracted from the data, with comments indicating their directionality.\n",
    "\n",
    "\n",
    "<- A is the source of B\n",
    "\n",
    "-> B is the source of A\n",
    "\n",
    "\n",
    "- \"rel:etymology\"               ->\n",
    "- \"rel:etymological_origin_of\"  <-\n",
    "- \"rel:is_derived_from\"         ->\n",
    "- \"rel:has_derived_form\"        <-\n",
    "- \"rel:etymologically_related\"  <->\n",
    "- \"rel:variant:orthography\"     <->\n",
    "\n",
    "source data also includes a handful of malformed values, which should be dropped or replaced \n",
    "- \"rel:etymologically\" -> \"rel:etymologically_related\"\n",
    "- \"rel:derived\" -> \"rel:is_derived_from\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Clean data\n",
    "\"\"\"\n",
    "\n",
    "# filter out bidirectional relationships and select one directionality to normalize the graph\n",
    "# I would normally clean to fix a handful of malformed tags as below but we are dropping those edge types anyway\n",
    "# so instead we will stick to the edge types that point from root words to derived words\n",
    "root_first_rel_types = [\"rel:etymological_origin_of\", \"rel:has_derived_form\"]\n",
    "cleaned_df = cleaned_df.loc[(cleaned_df[\"edge_type\"].isin(root_first_rel_types))]\n",
    "cleaned_df[[\"source_language\", \"source_word\"]] = cleaned_df.source_node.str.split(\n",
    "    \": \", expand=True\n",
    ")\n",
    "\n",
    "# there are a handful of nodes that include strange characters or a :Category: tag that introduces a third\n",
    "# column for no reason. This data is uninteresting so we can just ignore it and no include it in the graph when we construct it\n",
    "cleaned_df[[\"target_language\", \"target_word\", \"crud\"]] =  cleaned_df.target_node.str.split(\": \", expand=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'ave', 'frk', 'xno', 'hif', 'sot', 'sun', 'cic', 'jbo', 'umu', 'twf', 'ara', 'tam', 'adt', 'ast', 'mar', 'lij', 'grn', 'kri', 'auc', 'chc', 'kan', 'heb', 'slv', 'chr', 'kjh', 'urd', 'ukr', 'tha', 'szl', 'lim', 'mod', 'p_gmw', 'frp', 'lkt', 'gla', 'tew', 'tat', 'xon', 'rom', 'hye', 'chu', 'tuk', 'sco', 'slk', 'syc', 'haw', 'efi', 'p_sla', 'nor', 'aaq', 'dan', 'ppl', 'wit', 'akk', 'xng', 'txb', 'lmo', 'zko', 'gsw', 'tsn', 'aii', 'hsb', 'nap', 'arw', 'vls', 'byn', 'san', 'kur', 'swa', 'nob', 'pro', 'rap', 'tgl', 'ota', 'gwi', 'cym', 'cha', 'sme', 'nld', 'wln', 'nan', 'dsb', 'zai', 'gmy', 'ksd', 'tnq', 'tir', 'ron', 'sms', 'ike', 'mri', 'dtd', 'eus', 'som', 'odt', 'oji', 'fry', 'rme', 'stg', 'ben', 'sqi', 'ryu', 'sux', 'sei', 'min', 'epo', 'quc', 'nys', 'see', 'xho', 'mxi', 'prg', 'ksh', 'xaa', 'lua', 'frm', 'mya', 'glv', 'cor', 'osp', 'mal', 'nah', 'kaw', 'ccc', 'hak', 'sat', 'bod', 'ase', 'ale', 'ltc', 'fro', 'gez', 'por', 'mic', 'ood', 'rue', 'abs', 'kmb', 'mfr', 'vai', 'oge', 'gil', 'pml', 'hit', 'ltz', 'xtg', 'mnk', 'ton', 'wrh', 'lav', 'obt', 'nci', 'ang', 'pal', 'fur', 'aym', 'tah', 'xmb', 'gle', 'lng', 'crh', 'que', 'kaz', 'ell', 'oss', 'kzj', 'ofs', 'arg', 'cho', 'cat', 'fin', 'ina', 'fij', 'bis', 'deu', 'mlg', 'krl', 'ipk', 'bak', 'osx', 'xpr', 'hin', 'enm', 'nep', 'bdy', 'glg', 'yxg', 'bft', 'guj', 'iku', 'kir', 'xcl', 'pcd', 'arn', 'lad', 'lld', 'rmq', 'ndo', 'kin', 'kon', 'hun', 'rmf', 'tet', 'lug', 'khm', 'uzb', 'arz', 'lin', 'pan', 'che', 'swe', 'pol', 'tcs', 'vep', 'hat', 'est', 'enn', 'amj', 'ewe', 'tgk', 'pap', 'div', 'p_gem', 'scn', 'roh', 'cop', 'yid', 'dum', 'mbc', 'fao', 'srn', 'mav', 'aze', 'axm', 'evn', 'apw', 'gml', 'lat', 'ett', 'umb', 'nov', 'vma', 'srd', 'mon', 'ces', 'ayl', 'wam', 'csb', 'rus', 'kor', 'arq', 'afr', 'ruo', 'mah', 'fra', 'ess', 'hur', 'twi', 'orc', 'nds', 'zku', 'nno', 'srs', 'grc', 'ava', 'bel', 'luo', 'eng', 'ori', 'kld', 'mas', 'ary', 'pjt', 'bar', 'fon', 'sin', 'spa', 'egy', 'idb', 'xce', 'pli', 'cre', 'moe', 'ulk', 'mnc', 'pdt', 'isl', 'mlt', 'oco', 'xnt', 'naq', 'yor', 'kok', 'p_ine', 'rhg', 'lzh', 'rop', 'rup', 'lou', 'jam', 'mak', 'sth', 'tiv', 'pox', 'gmh', 'bua', 'stq', 'otk', 'vie', 'mwl', 'wlm', 'abe', 'akz', 'yua', 'tpi', 'peo', 'non', 'gul', 'kju', 'sga', 'bre', 'zsm', 'fas', 'okm', 'yur', 'obr', 'smo', 'pau', 'moh', 'alq', 'ceb', 'tpw', 'vec', 'hop', 'cmn', 'lut', 'xbm', 'shh', 'vol', 'kal', 'yol', 'pus', 'ikt', 'mkd', 'goh', 'wol', 'grv', 'kum', 'kat', 'ind', 'msa', 'ido', 'jpn', 'amh', 'kbd', 'lao', 'uig', 'orv', 'pim', 'qwc', 'zul', 'del', 'gae', 'wym', 'hbs', 'sna', 'mga', 'nav', 'nay', 'frc', 'jav', 'yue', 'hil', 'kky', 'phn', 'pis', 'tcy', 'tur', 'gug', 'hau', 'ain', 'emn', 'bul', 'owl', 'oci', 'ita', 'tel', 'got', 'inz', 'chn', 'dep', 'lit', 'myv'}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Get list of unique languages in data set.\n",
    "\n",
    "Not super necessary but helpful for understanding the likely subgraph structure. I would guess that the individual\n",
    "languages will be highly connected/clustered. I suspect the boundaries will blur a bit around the proto- and ancient languages, particularly for languages with\n",
    "many ancestors in the data set, e.g., Latin\n",
    "\"\"\"\n",
    "\n",
    "unique_languages = set(cleaned_df[\"source_language\"].unique()).union(set(cleaned_df[\"target_language\"].unique()))\n",
    "print(sorted(unique_languages))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Name: \nType: DiGraph\nNumber of nodes: 2743118\nNumber of edges: 2692096\nAverage in degree:   0.9814\nAverage out degree:   0.9814\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Construct networkx graph\n",
    "\"\"\"\n",
    "\n",
    "# start with directed so we can preserve directionality data, retaining the option to convert to undirected later to use networkx undirected algorithms\n",
    "graph = nx.from_pandas_edgelist(\n",
    "    cleaned_df,\n",
    "    edge_attr=[\n",
    "        \"edge_type\",\n",
    "        \"source_language\",\n",
    "        \"source_word\",\n",
    "        \"target_language\",\n",
    "        \"target_word\",\n",
    "    ],\n",
    "    source=\"source_node\",\n",
    "    target=\"target_node\",\n",
    "    create_using=nx.DiGraph,\n",
    ")\n",
    "print(nx.info(graph))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# What next?\n",
    "\n",
    "Now that we've loaded the data into a graph, it's time to do some actual analysis. But to do so, we need to define the problem more clearly. Otherwise, there is\n",
    "an intractable amount of data for many graph algorithms. Pruning to relevant subgraphs would be desirable as an initial post-processing step.\n",
    "\n",
    "I am primarily interested in English language entries. However, ~~many~~ all of the English words are derived from non-English words. It would be good to prune\n",
    "entries that are not etymological roots of English words.\n",
    "\n",
    "My initial instinct is to trim any descendant nodes of English words that are in other languages. Then, we can run BFS from each English node to gather its\n",
    "ancestors, knowing the descendant nodes have already been trimmed. This could accidentally exclude relevant data if there are derivation paths that jump from\n",
    "English to another language and then back, but that's an interesting question in and of itself and might be worth investigating as preliminary matter before\n",
    "pursuing this approach. \n",
    "\n",
    "However, I suspect the BFS approach may be extremely inefficient and that it will be necessary to reduce the size of the search space to something more\n",
    "tractable. \n",
    "\n",
    "So. What exactly are we looking for?\n",
    "\n",
    "- Nodes with the \"eng:\" prefix\n",
    "- Nodes that are direct and indirect ancestors of the English nodes\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Name: \nType: Graph\nNumber of nodes: 2743118\nNumber of edges: 2690896\nAverage degree:   1.9619\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Undirected graph analysis\n",
    "\n",
    "Construct undirected graph\n",
    "\"\"\"\n",
    "\n",
    "# convert to undirected so we can apply undirected algorithms\n",
    "undirected_graph = graph.to_undirected()\n",
    "print(nx.info(undirected_graph))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "209375\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Undirected graph analysis\n",
    "\n",
    "Check for connected components\n",
    "\"\"\"\n",
    "\n",
    "from networkx.algorithms.components import connected_components\n",
    "\n",
    "# check for connected components. may be a way to prune subgraphs that do not relate to English etymology\n",
    "count = sum([1 for _ in connected_components(undirected_graph)])\n",
    "print(count)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Create English-related subgraph\n",
    "\"\"\"\n",
    "\n",
    "# grab the nodes that have the eng tag, then build the connected graph from those\n",
    "english_nodes = [n for n in graph.nodes() if n[0:3] == 'eng']\n",
    "nodes_to_add = []\n",
    "# add nodes inside loop to avoid having to flatten later\n",
    "[nodes_to_add.extend(bfs_tree(graph, source=node)) for node in english_nodes]\n",
    "\n",
    "english_graph = graph.subgraph(nodes_to_add)\n",
    "print(nx.info(english_graph))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-120a45c5006e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnodes_by_degree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_by_degree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'english_graph' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'english_graph' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "nodes_by_degree = sorted(english_graph.degree, key=lambda x: x[1], reverse=True)\n",
    "print(nodes_by_degree[0:99])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}